"""
Cross-site scripting (XSS) detection rule.

Detects potential XSS vulnerabilities from unescaped HTML output,
innerHTML assignments, and other DOM manipulation risks.
"""

import re
from typing import TYPE_CHECKING

from ..base import BaseRule, Evidence, Finding, RuleContext, Severity, Trigger

if TYPE_CHECKING:
    pass


class XSSVulnerabilityRule(BaseRule):
    """Detect potential XSS vulnerabilities."""

    # Language-specific patterns for XSS
    # Format: (pattern, description, confidence)
    PATTERNS = {
        "python": [
            # innerHTML in Python (templates/server-rendered)
            (
                r'\.innerHTML\s*=',
                "innerHTML assignment (potential XSS)",
                0.85,
            ),
            # render_template_string with variables
            (
                r'render_template_string\s*\([^)]*[\+\{%]',
                "render_template_string with variable interpolation",
                0.90,
            ),
            # Jinja2 |safe filter
            (
                r'\|\s*safe\b',
                "Jinja2 |safe filter bypasses escaping",
                0.80,
            ),
            # Django mark_safe
            (
                r'mark_safe\s*\(',
                "Django mark_safe() bypasses escaping",
                0.80,
            ),
            # format_html without escaping
            (
                r'format_html\s*\([^)]*[\+\{]',
                "format_html with dynamic content",
                0.70,
            ),
            # Direct HTML in HttpResponse
            (
                r'HttpResponse\s*\(\s*[^)]*<\s*(script|iframe|img)',
                "HTML in HttpResponse (potential XSS)",
                0.85,
            ),
            # Mako ${...} without h: filter
            (
                r'\$\{[^}]*\}(?!\s*\|\s*h)',
                "Mako template without h: filter",
                0.70,
            ),
        ],
        "javascript": [
            # innerHTML assignment
            (
                r'\.innerHTML\s*=(?!.*(?:DOMPurify|sanitize|escape))',
                "innerHTML assignment without sanitization",
                0.90,
            ),
            # outerHTML assignment
            (
                r'\.outerHTML\s*=',
                "outerHTML assignment (potential XSS)",
                0.90,
            ),
            # document.write
            (
                r'document\.write\s*\(',
                "document.write() is XSS-prone",
                0.85,
            ),
            # insertAdjacentHTML
            (
                r'\.insertAdjacentHTML\s*\(',
                "insertAdjacentHTML without sanitization",
                0.80,
            ),
            # dangerouslySetInnerHTML in React
            (
                r'dangerouslySetInnerHTML\s*=',
                "React dangerouslySetInnerHTML (review for XSS)",
                0.85,
            ),
            # jQuery html() with variable
            (
                r'\$\([^)]+\)\.html\s*\([^)]*[\+\`]',
                "jQuery .html() with dynamic content",
                0.85,
            ),
            # eval-like constructs
            (
                r'\beval\s*\([^)]*[\+\`]',
                "eval() with dynamic content (XSS/injection risk)",
                0.95,
            ),
            # document.createElement('script')
            (
                r'createElement\s*\(\s*["\']script["\']',
                "Dynamic script creation (review for XSS)",
                0.75,
            ),
            # URL-based XSS (javascript: protocol)
            (
                r'(href|src)\s*=\s*["\']?javascript:',
                "javascript: protocol (XSS vector)",
                0.95,
            ),
            # location assignment
            (
                r'(window\.)?location(\.href)?\s*=\s*[^;]+[\+\`]',
                "Dynamic location assignment (potential XSS)",
                0.80,
            ),
        ],
        "typescript": [
            # Same as JavaScript
            (
                r'\.innerHTML\s*=(?!.*(?:DOMPurify|sanitize|escape))',
                "innerHTML assignment without sanitization",
                0.90,
            ),
            (
                r'dangerouslySetInnerHTML\s*=',
                "React dangerouslySetInnerHTML (review for XSS)",
                0.85,
            ),
            (
                r'document\.write\s*\(',
                "document.write() is XSS-prone",
                0.85,
            ),
            (
                r'\.insertAdjacentHTML\s*\(',
                "insertAdjacentHTML without sanitization",
                0.80,
            ),
        ],
        "php": [
            # Echo without escaping
            (
                r'echo\s+\$(?!.*(?:htmlspecialchars|htmlentities|esc_|e\())',
                "echo with variable (potential XSS)",
                0.75,
            ),
            # Print without escaping
            (
                r'print\s+\$',
                "print with variable (potential XSS)",
                0.75,
            ),
            # Short echo tag
            (
                r'<\?=\s*\$',
                "Short echo tag with variable (potential XSS)",
                0.80,
            ),
            # Response output
            (
                r'Response::(write|output)\s*\([^)]*\$',
                "Response output with variable (potential XSS)",
                0.80,
            ),
        ],
        "java": [
            # PrintWriter without encoding
            (
                r'(PrintWriter|response\.getWriter\(\)).*\.print(ln)?\s*\([^)]*\+',
                "Direct output with concatenation (potential XSS)",
                0.80,
            ),
            # JSP expression
            (
                r'<%=\s*[^%]*%>',
                "JSP expression (ensure proper escaping)",
                0.70,
            ),
            # Spring ResponseBody without escaping
            (
                r'@ResponseBody.*return\s+[^;]*\+',
                "ResponseBody with concatenation (potential XSS)",
                0.75,
            ),
        ],
        "ruby": [
            # raw helper
            (
                r'\braw\s*\(',
                "raw() bypasses HTML escaping",
                0.80,
            ),
            # html_safe
            (
                r'\.html_safe\b',
                "html_safe bypasses escaping",
                0.80,
            ),
            # ERB without escaping
            (
                r'<%=\s*.*\s*%>',
                "ERB output (verify escaping)",
                0.60,
            ),
            # content_tag with unsafe content
            (
                r'content_tag\s*\([^)]*raw\s*\(',
                "content_tag with raw content",
                0.85,
            ),
        ],
    }

    @property
    def rule_id(self) -> str:
        return "SECURITY.XSS_VULNERABILITY"

    @property
    def name(self) -> str:
        return "XSS Vulnerability Detection"

    @property
    def category(self) -> str:
        return "security"

    @property
    def default_severity(self) -> Severity:
        return Severity.CRITICAL

    @property
    def triggers(self) -> list[Trigger]:
        return [Trigger.ON_WRITE, Trigger.ON_STOP, Trigger.ON_COMMIT]

    @property
    def supported_languages(self) -> list[str] | None:
        return list(self.PATTERNS.keys())

    @property
    def description(self) -> str:
        return (
            "Detects potential Cross-Site Scripting (XSS) vulnerabilities "
            "from unescaped output, innerHTML assignments, and unsafe DOM manipulation."
        )

    @property
    def is_fast(self) -> bool:
        return True

    def _has_sanitization(self, line: str, surrounding_lines: list[str]) -> bool:
        """Check if sanitization is present nearby."""
        sanitization_patterns = [
            r'DOMPurify',
            r'sanitize',
            r'escape',
            r'htmlspecialchars',
            r'htmlentities',
            r'encodeURI',
            r'encodeURIComponent',
            r'textContent',
            r'createTextNode',
            r'\.text\s*\(',
            r'html\.escape',
            r'cgi\.escape',
            r'escape_html',
            r'strip_tags',
            r'xss',
        ]
        text_to_check = line + " " + " ".join(surrounding_lines)
        for pattern in sanitization_patterns:
            if re.search(pattern, text_to_check, re.IGNORECASE):
                return True
        return False

    def check(self, context: RuleContext) -> list[Finding]:
        """Check for XSS vulnerabilities.

        Args:
            context: RuleContext with file content

        Returns:
            List of findings for detected XSS risks
        """
        findings = []
        language = context.language

        # Get patterns for this language
        patterns = self.PATTERNS.get(language, [])
        if not patterns:
            return findings

        file_path_str = str(context.file_path)

        # Check if this is a test file
        is_test_file = any(
            marker in file_path_str.lower()
            for marker in ["test_", "_test", "tests/", "spec/", "mock/", "fixture"]
        )

        lines = context.lines

        for line_num, line in enumerate(lines, start=1):
            # Skip if line not in diff
            if not context.is_line_in_diff(line_num):
                continue

            # Skip comment lines
            stripped = line.strip()
            if stripped.startswith("#") or stripped.startswith("//") or stripped.startswith("*"):
                continue

            # Skip lines with nosec markers
            if "nosec" in line.lower() or "noqa" in line.lower():
                continue

            for pattern, description, base_confidence in patterns:
                if re.search(pattern, line, re.IGNORECASE):
                    # Get surrounding lines for context
                    start = max(0, line_num - 5)
                    end = min(len(lines), line_num + 3)
                    surrounding = lines[start:end]

                    # Lower confidence if sanitization is present
                    if self._has_sanitization(line, surrounding):
                        continue  # Skip if sanitization found

                    if is_test_file:
                        confidence = base_confidence * 0.5
                    else:
                        confidence = base_confidence

                    findings.append(
                        self._create_finding(
                            summary=f"Potential XSS: {description}",
                            file_path=file_path_str,
                            line_number=line_num,
                            evidence=[
                                Evidence(
                                    description=description,
                                    line_number=line_num,
                                    code_snippet=line.strip(),
                                    data={
                                        "language": language,
                                        "is_test_file": is_test_file,
                                    },
                                )
                            ],
                            remediation_hints=self._get_remediation_hints(language),
                            confidence=confidence,
                        )
                    )
                    break  # Only report first match per line

        return findings

    def _get_remediation_hints(self, language: str) -> list[str]:
        """Get language-specific remediation hints."""
        hints = {
            "python": [
                "Use Django's autoescape or mark content as escaped",
                "In Flask/Jinja2, avoid |safe filter unless content is sanitized",
                "Use bleach library to sanitize HTML content",
            ],
            "javascript": [
                "Use textContent instead of innerHTML for text-only content",
                "Use DOMPurify.sanitize() before inserting HTML",
                "In React, avoid dangerouslySetInnerHTML when possible",
            ],
            "typescript": [
                "Use textContent instead of innerHTML for text-only content",
                "Use DOMPurify or similar for HTML sanitization",
                "Leverage TypeScript's type system to track sanitized content",
            ],
            "php": [
                "Use htmlspecialchars() with ENT_QUOTES for output",
                "Use templating engines with auto-escaping enabled",
                "Consider using HTMLPurifier for rich HTML content",
            ],
            "java": [
                "Use OWASP Java Encoder for output encoding",
                "Use JSP c:out tag or fn:escapeXml() function",
                "Enable auto-escaping in your template engine",
            ],
            "ruby": [
                "Let Rails auto-escape; avoid raw() and html_safe unless necessary",
                "Use sanitize() helper for user-provided HTML",
                "Review any use of html_safe carefully",
            ],
        }
        return hints.get(language, [
            "Always escape/encode user input before rendering as HTML",
            "Use Content Security Policy (CSP) headers as defense in depth",
            "Use a sanitization library appropriate for your framework",
        ])
